# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую линейную метрику, чтобы программа отрабатывала за линейное время выполнения в зависимости от размера входных данных.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 0.84551 сек.

Вот как я построил `feedback_loop`: взял из большого файла первые 1000 строк
head -n 1000 data_large.txt > data1000.txt
отработало за 0.018932 сек.

Затем взял первые 10000 строк - отработала за 0.84551 сек.
Взял первые 20000 строк - отработала за 3.424572
Взял первые 30000 строк - отработала за 7.557747
Взял первые 100000 строк - не дождался, но было точно 100+ сек.

Таким образом, остановился на 10000 строках и заодно проанаизировал зависимость, котороая являлась степенной или экспоненциальной, как можно было увидеть из примеров выше.

## Вникаем в детали системы, чтобы найти главные точки роста

Сначала написал тест на производительность, в файле benchmark.rb. По мере исправлений я менял входные данные для метода work, чтобы не выходить за рамки 30 сек, т.е. сначала улучшил для 100000 строк время отработки, чтобы отрабатывало меньше чем за 30 сек, , зачем для 500000, и т.д. А так же написал тест который проверяет линейную зависимость, в начале, конечно же, который провалился, тем самым подтвердив не линейную зависимость, которая была выявлена еще при построении Feedback-Loop, сообщения теста были следующие
- expected block to perform linear, but performed exponential
- expected block to perform linear, but performed logarithmic
- expected block to perform linear, but performed power
Любые, но не линейная

Для того, чтобы найти "точки роста" для оптимизации я несколькими воспользовался инструментами, которые были представлены в первой недели лекции. Это FlatPrinter, GraphHtmlPrinter, и самый информативный, на мой взгляд, это CallTreePrinter, так как по построенному дереву можно сразу увидеть не только метод, который дольше всего отрабатывает, но и все дочерние методы в виде дерева в процентах, сколько каждый из них потребляет. Сначала достаточно было более простых профилировщиков - FlatPrinter, GraphHtmlPrinter, но ближе к концу более информативным и более наглядным оказался CallTreePrinter!

Вот какие проблемы удалось найти и решить

### Находка №1
- Flat сразу указал на главную точку роста. Это был метод select, который занимал 62% времени выполнения
- Заменил метод select методом group_by, разбив все сессии пользователей за один проход
- Для 10000 строк стало отрабатывать за 0.196914 сек. - было 0.84551 сек. -> в 4+ раза быстрее
- Отчет профилировщика изменился, исправленная проблема перестала быть главной точкой роста
